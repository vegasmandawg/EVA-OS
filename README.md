<div align="center">
  <a href="./README.md">
    <img src="https://img.shields.io/badge/ğŸ‡ºğŸ‡¸_English-2980b9" alt="English">
  </a>
  &nbsp;
  <a href="./README-zh.md">
    <img src="https://img.shields.io/badge/ğŸ‡¨ğŸ‡³_ç®€ä½“ä¸­æ–‡-d35400" alt="ç®€ä½“ä¸­æ–‡">
  </a>

  <br>
  <a href="./LICENSE"><img src="https://img.shields.io/badge/license-MIT-green?style=flat-square" alt="License"></a>
  <img src="https://img.shields.io/badge/platform-iOS%20%7C%20Android%20%7C%20IoT-lightgrey?style=flat-square" alt="Platform">
  <a href="https://eva.autoarkai.com"><img src="https://img.shields.io/badge/website-eva.autoarkai.com-blue?style=flat-square" alt="Website"></a>
  <a href="https://github.com/AutoArk/EVA-OS/stargazers"><img src="https://img.shields.io/github/stars/AutoArk/EVA-OS?style=social" alt="Stars"></a>
</div>

# **EVA OS â€” Real-Time Multimodal AIOS for the Next Generation Hardware**

> âš¡ Real-time Â· ğŸ“¡ WebRTC Â· ğŸ™ï¸ Multi-Voice Â· ğŸ§  EVA-flash Â· ğŸ”Œ Embedded Ready  
>  
> Multimodal interaction powering intelligent devices Â· Instantly upgrade any hardware into a real-time multimodal AI terminal

![Image](https://github.com/user-attachments/assets/becd21cd-f5f8-46c4-a8f5-6d11ddb73ac9)

## ğŸš€ Milestone Updates | Latest Updates

**[2026-01-23] EVA OS v1.0.2 Launched!**

* **ğŸš€ Experience Upgrade**: Enhanced speech recognition and speech synthesis capabilities, more accurate and faster.
* **ğŸ—£ï¸ New AI Agents**: Added several built-in Agents including interpreters and dialect companions.
* **ğŸ›¡ï¸ Immersive Mode**: Built-in Agents support mode takeover, requiring an explicit exit command to quit.
* **ğŸ“ Location Awareness**: Reports location information when using Amap MCP.(authorization required)

**[2025-12-26] Release Â· EVA OS v1.0.1 Launched!**

* â€‹**ğŸŒ Python SDK**â€‹: We provide a python version client SDK, for easier development on your device
* **ğŸ› ï¸ Customized MCP Tools**â€‹: User can config any online MCP tools in your own solution!
* â€‹**ğŸ”‘ Share your solution to your friend**â€‹: Share your solution to your friend in one click, with full functions.

**[2025-12-07] Release Â· EVA OS v1.0.0 Officially Launched!**

* â€‹**ğŸ§ Full Duplex Interaction**â€‹: millisecond-level latency, supports barge-in during conversations, achieving truly human-like real-time dialogue
* **ğŸ› ï¸ MCP Tools Suite**â€‹: built-in weather forecast, web search, smart map and more utilities, works out-of-the-box
* **ğŸ™ï¸ Multi-Voice TTS Engine**â€‹: added 10+ humanlike voices (emotional voices, professional broadcast voices and so on), switch in one click within a Solution
* â€‹**ğŸ§  Agent Workflow / Multi-Agent Collaboration System**â€‹: enables cross-capability cooperation for complex tasks such as poem creation and story generation
* â€‹**ğŸ”‘ SDK Release / Fully Open Source**â€‹: iOS & Android SDKs are now completely opensourced, providing zero-barrier hardware integration
* â€‹**ğŸŒ LiveKit Deep Optimization**â€‹: ultra-low latency full-duplex communication

## ğŸ”® About EVA OS Â· Core Positioning

EVA OS is an **open-source, multimodal, low-latency** real-time AI Agent engine designed for next-generation AI hardware. It is deeply optimized for mobile devices, IoT hardware, and embedded systems. It fills the gap between â€œdevice intelligenceâ€ and â€œuser experience.â€

Through the EVA platform, developers can quickly create Solutions (AI Agents) with real-time multimodal interaction, and with a single API Key achieving **â€œdevelop once, run on all devices.â€** Any hardware can instantly become a â€œreal-time multimodal interactive, agent-cooperative, memory-capable AI hub.â€

> Core Benefits: EVA-flash model permanently free | Mobile SDK 100% open source | ESP32/RK/MCU embedded SDK coming soon

![Image](https://github.com/user-attachments/assets/4815de5b-4f2f-4ab7-8803-8d4445781d0c)
## **ğŸ§  The Vision Behind EVA OS**

Our belief:

* Foundation models are merely â€œneuronsâ€
* AI hardware needs a â€œnervous systemâ€
* **EVA OS aims to become the nervous system of next-generation AI devices**

![Image](https://github.com/user-attachments/assets/c2a7f170-b0e9-44d5-ad6d-cd830fcfe328)
### **AIOS (AI Operating System)** is defined as â€œthe nervous system of next-generation AI hardwareâ€

* **â€‹Interaction Layerï¼šâ€‹** From **single-modality** to **multi-modality**  
  The system can simultaneously understand text, speech, images, video, etc. It also supports barge-in, speech interruption, and real-time responsiveness, making AI â€œconverse like a human.â€

* **â€‹Memory Layerï¼š** â€‹From **text** memory to **multimodal** memory
  And from **storage-based** memory to **parameterized** memory.  
  The AI remembers not only text, but also images, audio, and contextual modalities â€”- making memory deeper and more integrated.

* **Execution Layerï¼š** From **simple API calls to complex reasoning**
  EVA OS evolves from executing fixed commands to performing logical reasoning and solving complex tasks.

* **Persona Layer (Representation)ï¼š** From **programmed behavior to model-driven dynamics**  
  The AIâ€™s â€œpersonaâ€ becomes dynamic, adaptive, and humanlikeâ€”shaped by large model reasoning rather than rigid code.

## **âœ¨ EVA OS 1.0 Features**

### âš¡ Core Advantages Â· Defining the New Paradigm of AI OSâ€“Level Hardware Interaction

#### ğŸ§  EVA-flash: Hardware-Friendly Real-Time Multimodal LM

* Streaming architecture with response latency as low as 300ms
* Native multimodal support: speech, vision, text
* Lightweight optimization for mid-range hardware

#### ğŸ“± Full-Stack Open-Source SDK Â· Zero Barrier Integration

* iOS/Android SDK fully open source with detailed demos
* ESP32/RK/MCU embedded SDK in final testing
* Best-practice samples for IoT / toys / speakers

#### ğŸ˜² Digital Avatar Engine

* Real-time lip-sync
* Multiple default avatars included
* Custom user-generated avatars coming soon

#### ğŸ”Š Multi-Voice Audio/Video Interaction

* 10+ humanlike voices with emotional modulation
* Full-duplex communication with natural barge-in
* Smart auto-response + customizable greetings

#### ğŸŒ WebRTC Global Real-Time Connectivity

* Real-time audio/video streaming
* Truly full-duplexâ€”no: more â€œwaiting for replyâ€ gaps

#### ğŸ§© Highly Configurable AI Agent Framework

* Custom prompt templates for education, home, office, etc.
* Multi-Agent routing for complex task orchestration
* Built-in MCP tools for personalized functions

#### ğŸŒ Ecosystem Matrix Â· Full-Scenario AI Hardware Coverage

* Unified Solution API Key supporting mainstream hardware
* Fully open resources: SDKs, sample projects, docs
* [Coming Soon]: Embedded system SDK, edge-cloud collaboration, embodied intelligence APIs

---

## **ğŸš€ Quick Start**

**1ï¸âƒ£ Register an EVA Platform Account**

Visit: **https://eva.autoarkai.com**

Create:

* Solution
* Configure Voices, Prompts, Tools, Agents
* Obtain API Key

**2ï¸âƒ£ Use API Key to Generate a LiveKit Token**

Refer to the example in the mobile SDK:  
[eva-client.ts](https://github.com/AutoArk/EVA-OS/blob/main/eva-mobile/README.md#3-reference-implementation)

**3ï¸âƒ£ Client Connection Example**

Refer to React Native example:  
[React Native Example Docs](https://github.com/AutoArk/EVA-OS/blob/main/eva-mobile/README.md#3-reference-implementation)

## **ğŸ—ºï¸ Roadmap**

### **âœ… Completed**

* ğŸ§ Real-time full-duplex audio/video interaction
* âš¡ EVA-flash real-time multimodal LM 
* ğŸ§© Solution (AI Agent) framework
* ğŸ”‘ API Key device access
* ğŸ“± iOS & Android SDK fully open source
* ğŸ› ï¸ Built-in MCP Tools

### ğŸš€ Coming Soon

* ğŸ”Œ Embedded SDK: ESP32/RK/MCU hardware-level integration
* â˜ï¸ Edge-Cloud Collaboration: cloud compute scheduling + precise device-side command delivery
* ğŸ§  Intelligent Memory: short-term interaction memory + long-term preference memory
* ğŸ”§ MCP Tool Extensions: third-party tool integration
* ğŸ­ Custom Digital Avatars: generate avatars from costomized photos
* ğŸ¢ Enterprise Features: hybrid model deployment + high-concurrency solutions

---

## **ğŸ¤ Join the EVA Open-Source Ecosystem**

### Join the Ecosystem Â· Building the Future of AI OS for Hardware

EVAâ€™s vision: empower every device with autonomous interaction, execution, and memory: awakening true hardware-level AI intelligence.

You are welcome whether you are:

* App developers  
* IoT / toy / smart home device/ robotics creators  
* Embedded engineers (ESP32 / RK / STM32)  
* DIY makers

You can contribute:

* PRs (optimize mobile SDK)
* Embedded integration examples
* Tutorials / documentation
* New language SDKs
* Device-side demos
* Issues / feature requests

**Letâ€™s build the most open and complete real-time multimodal AI hardware ecosystemâ€”together!**

## ğŸ“„ License

EVA OS is released under the MIT License.

This means you are free to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, as long as you include the original copyright and permission notice in any copies or substantial portions.

## âš¡ Powered by

![Powered by](https://github.com/user-attachments/assets/7fcfd112-f14c-4356-9345-98761776bc95)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=AutoArk/EVA-OS&type=date&legend=top-left)](https://www.star-history.com/#AutoArk/EVA-OS&type=date&legend=top-left)
